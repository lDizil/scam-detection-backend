# Архитектура и работа ML модели

## Обзор

Мы используем модель **BERT**, дообученную на задаче детекции фишинга. Это state-of-the-art подход для классификации текстов.

## Модель: ealvaradob/bert-finetuned-phishing

### Базовая архитектура: BERT

**BERT** (Bidirectional Encoder Representations from Transformers) - это трансформерная модель от Google, которая понимает контекст слов в обе стороны (слева направо и справа налево).

#### Технические характеристики:

- **Параметры:** ~110 миллионов
- **Слои:** 12 трансформер-блоков
- **Hidden size:** 768
- **Attention heads:** 12
- **Максимальная длина:** 512 токенов
- **Словарь:** 30,000 токенов

#### Как работает:

```
Текст → Токенизация → Embedding → 12 слоев Transformer → Classification Head → Softmax → Вероятности
```

### Предобучение

BERT предобучен на огромном корпусе текстов:

- **Английская Wikipedia** (~2.5B слов)
- **BookCorpus** (~800M слов)

Задачи предобучения:

1. **Masked Language Model (MLM):** Предсказать замаскированные слова
   - Пример: "Я иду в [MASK]" → модель предсказывает "магазин"
2. **Next Sentence Prediction (NSP):** Определить, следует ли второе предложение за первым

### Дообучение на фишинге

Модель `ealvaradob/bert-finetuned-phishing` была дообучена на датасете фишинговых сообщений:

- **Датасет:** Коллекция реальных фишинговых и легитимных сообщений
- **Задача:** Бинарная классификация (phishing vs legitimate)
- **Классы:**
  - `0` - Legitimate (легитимный текст)
  - `1` - Phishing (фишинг/мошенничество)

## Что детектирует модель

### Детектит:

1. **Фишинговые сообщения от банков:**

   - "Ваша карта заблокирована. Перейдите по ссылке"
   - "Служба безопасности банка. Назовите CVV код"

2. **Поддельные призы и лотереи:**

   - "Вы выиграли 1 миллион! Переведите 500р для получения"
   - "Поздравляем! Вы победитель акции iPhone 15"

3. **Срочные запросы данных:**

   - "Срочно! Подтвердите данные карты в течение 24 часов"
   - "Ваш аккаунт будет удален. Перейдите по ссылке"

4. **Манипуляции через страх:**

   - "Обнаружена подозрительная активность"
   - "Ваш аккаунт заблокирован за нарушение"

5. **Поддельные технические поддержки:**
   - "Техподдержка Google. Для восстановления назовите пароль"
   - "Служба безопасности VK. Отправьте код из СМС"

### НЕ детектит:

1. **Токсичность и оскорбления** (нужна модель для hate speech)
2. **Грамматические ошибки** (нужна модель для grammar checking)
3. **Общий стиль текста** (нужна модель для style analysis)
4. **Изображения** (нужна CV модель)
5. **Вредоносные URL** (нужен URL analyzer)

## Процесс инференса

### Шаг 1: Токенизация

```
Текст: "Ваш аккаунт заблокирован"
↓
Токены: ["[CLS]", "ваш", "аккаунт", "заблокирован", "[SEP]"]
↓
Token IDs: [101, 2076, 4382, 15439, 102]
```

**Специальные токены:**

- `[CLS]` (101) - начало последовательности, используется для классификации
- `[SEP]` (102) - конец последовательности
- `[PAD]` (0) - дополнение коротких текстов до 512 токенов
- `[UNK]` (100) - неизвестные слова

### Шаг 2: Embedding

Каждый токен конвертируется в вектор размерности 768:

```
Token ID 2076 ("ваш") → [0.234, -0.567, 0.123, ..., 0.891] (768 чисел)
```

Три типа эмбеддингов суммируются:

1. **Token Embeddings** - значение слова
2. **Position Embeddings** - позиция в предложении
3. **Segment Embeddings** - какое это предложение (для NSP задачи)

### Шаг 3: Transformer блоки

Текст проходит через 12 слоев трансформеров:

```
Слой 1:  Attention → Layer Norm → Feed Forward → Layer Norm
         ↓
Слой 2:  Attention → Layer Norm → Feed Forward → Layer Norm
         ↓
         ... (еще 10 слоев)
         ↓
Слой 12: Attention → Layer Norm → Feed Forward → Layer Norm
```

**Self-Attention механизм:**

- Модель смотрит на все слова одновременно
- Понимает связи между словами ("ваш" → "аккаунт")
- 12 attention heads позволяют фокусироваться на разных аспектах

**Пример attention:**

```
"Ваш аккаунт заблокирован"
         ↓
"ваш" обращает внимание на "аккаунт" (связь)
"заблокирован" обращает внимание на "аккаунт" (действие над объектом)
```

### Шаг 4: Classification Head

Берется вектор токена `[CLS]` из последнего слоя (768 чисел):

```
[CLS] vector (768) → Linear Layer (768 → 2) → Logits
```

**Logits** - сырые предсказания для каждого класса:

```
Logits: [2.3, -1.5]  # [legitimate, phishing]
```

### Шаг 5: Softmax

Логиты конвертируются в вероятности (сумма = 1.0):

```
Logits: [2.3, -1.5]
        ↓ Softmax
Probabilities: [0.9820, 0.0180]  # 98.2% legitimate, 1.8% phishing
```

### Шаг 6: Предсказание

Выбирается класс с максимальной вероятностью:

```
argmax([0.9820, 0.0180]) = 0 → Legitimate
```

## Примеры работы модели

### Пример 1: Фишинг (высокая уверенность)

**Текст:** "Срочно! Ваш аккаунт заблокирован. Перейдите по ссылке для разблокировки"

**Ключевые признаки, которые модель замечает:**

- "Срочно!" - создание паники
- "аккаунт заблокирован" - угроза потери доступа
- "перейдите по ссылке" - призыв к действию

**Attention карта (что важно для модели):**

```
Срочно!    [HIGH ATTENTION]
аккаунт    [HIGH ATTENTION]
заблокирован [HIGH ATTENTION]
ссылке     [MEDIUM ATTENTION]
```

**Результат:**

```json
{
  "label": "phishing",
  "confidence": 0.9765,
  "is_scam": true
}
```

### Пример 2: Легитимный текст

**Текст:** "Привет! Как дела? Созвонимся завтра в 15:00?"

**Ключевые признаки:**

- "Привет!" - дружеское приветствие
- "Как дела?" - обычный вопрос
- "Созвонимся завтра" - планирование, без угроз

**Attention карта:**

```
Привет     [LOW ATTENTION]
Как дела   [LOW ATTENTION]
Созвонимся [LOW ATTENTION]
15:00      [LOW ATTENTION]
```

**Результат:**

```json
{
  "label": "legitimate",
  "confidence": 0.9532,
  "is_scam": false
}
```

### Пример 3: Пограничный случай

**Текст:** "Ваш заказ готов к получению. Пожалуйста, подойдите в пункт выдачи"

**Особенности:**

- "Ваш заказ" - может быть как фишинг, так и легитимное уведомление
- "подойдите в пункт выдачи" - нет запроса личных данных

**Результат:**

```json
{
  "label": "legitimate",
  "confidence": 0.6543,
  "is_scam": true // Уверенность > 0.5, но небольшая
}
```

## Метрики и качество модели

### Типичные метрики для фишинг-детекции:

**Accuracy (точность):** ~90-95%

- Процент правильных предсказаний из всех

**Precision (точность positive класса):** ~92-96%

- Из всех, что модель назвала фишингом, сколько реально фишинг
- Важно для минимизации ложных срабатываний

**Recall (полнота):** ~88-93%

- Из всех реальных фишингов, сколько модель детектила
- Важно для максимального покрытия

**F1-Score:** ~90-94%

- Гармоническое среднее Precision и Recall

### Confusion Matrix (пример):

```
                Predicted
                Legit  Phish
Actual  Legit   450     20     (95.7% правильно)
        Phish    35    495     (93.4% правильно)
```

**Интерпретация:**

- 450 легитимных текстов правильно классифицированы
- 20 легитимных ошибочно помечены как фишинг (False Positive)
- 35 фишингов пропущены (False Negative)
- 495 фишингов правильно детектированы

## Настройка порога (Threshold)

По умолчанию `PHISHING_THRESHOLD=0.5`:

```python
is_scam = (label == "phishing" AND confidence >= 0.5)
```

### Как выбрать порог?

**Высокий порог (0.7-0.9):**

- Меньше ложных срабатываний (легитимные не блокируются)
- Больше пропусков (некоторые фишинги проходят)
- **Когда использовать:** Когда false positive критичны (например, блокировка сообщений)

**Средний порог (0.5-0.7):**

- Баланс между precision и recall
- **Когда использовать:** Большинство сценариев (по умолчанию)

**Низкий порог (0.3-0.5):**

- Детектим максимум фишингов
- Больше ложных срабатываний
- **Когда использовать:** Когда false negative критичны (нельзя пропустить фишинг)

### Пример настройки:

```env
# В ml-service/.env
PHISHING_THRESHOLD=0.7  # Более консервативный подход
```

## Ограничения модели

### 1. Максимальная длина: 512 токенов

```
~400-450 слов на английском
~300-350 слов на русском
```

Если текст длиннее, он обрезается. Можно:

- Разбить на части и анализировать по отдельности
- Использовать модель с большим context window (Longformer, BigBird)

### 2. Работа с русским языком

BERT предобучен на английском, но:

- Может работать с русским благодаря multilingual tokenizer
- Универсальные паттерны фишинга (угрозы, срочность) работают
- Для лучшего качества рекомендуется дообучить на русском датасете

### 3. Новые виды мошенничества

Модель знает паттерны из обучающих данных. Новые схемы могут не детектиться.

**Решение:** Периодически дообучать на свежих примерах

### 4. Контекстные фишинги

Сложные таргетированные атаки (spear phishing), которые выглядят очень правдоподобно:

```
"Привет, Иван! Напоминаю про встречу завтра в 15:00.
Кстати, не можешь оплатить счет от поставщика?
Вот ссылка на документ: evil-link.com"
```

Такие сообщения могут выглядеть легитимными для модели.

## Производительность

### Скорость инференса:

**CPU (Intel i7):**

- Один текст: ~200-500ms
- Батч 10 текстов: ~800-1200ms

**GPU (NVIDIA GTX 1660):**

- Один текст: ~50-100ms
- Батч 10 текстов: ~150-300ms

**GPU (NVIDIA RTX 3090):**

- Один текст: ~20-50ms
- Батч 10 текстов: ~80-150ms

### Память:

- **Модель:** ~440MB на диске
- **В RAM:** ~1-1.5GB
- **В VRAM (GPU):** ~1.2GB

## Дообучение (Fine-tuning)

### Когда нужно дообучать?

1. **У вас есть свои данные** (мин. 1000 примеров)
2. **Специфическая доменная область** (банковские SMS, email рассылки)
3. **Низкое качество на ваших данных** (< 85% accuracy)
4. **Новые типы мошенничества** появились

### Процесс дообучения:

1. **Подготовка данных:**

   ```csv
   text,label
   "Срочно! Аккаунт заблокирован",1
   "Привет, как дела?",0
   ```

2. **Запуск обучения:**

   ```bash
   cd ml-service
   python training/train.py
   ```

3. **Параметры обучения:**

   - Learning rate: 2e-5 (стандарт для BERT)
   - Batch size: 16-32 (зависит от памяти)
   - Epochs: 3-5 (больше = overfitting)
   - Warmup steps: 500

4. **Оценка качества:**

   - Проверить на тестовой выборке
   - Precision > 0.90, Recall > 0.85

5. **Деплой:**
   ```env
   CUSTOM_MODEL_PATH=./training/models/my_model
   ```

Подробнее: [training/README.md](training/README.md)

## Альтернативные подходы

### Для улучшения качества:

1. **RoBERTa** - улучшенная версия BERT
2. **DistilBERT** - облегченная версия (быстрее, но -2% accuracy)
3. **ELECTRA** - эффективнее обучается
4. **DeBERTa** - state-of-the-art по качеству

### Для других задач:

1. **GPT-3/4** - zero-shot классификация (дорого)
2. **LLaMA** - open-source альтернатива GPT
3. **Ensemble модели** - комбинация нескольких моделей
4. **Rule-based + ML** - гибридный подход

## Полезные ресурсы

- [BERT Paper](https://arxiv.org/abs/1810.04805)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers/)
- [Модель на HuggingFace](https://huggingface.co/ealvaradob/bert-finetuned-phishing)
- [Fine-tuning BERT](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)
